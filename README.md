# PySpark_Spark_Data_Analytics
Neste projeto, foi feita a análise dos mesmos dados do meu projeto Hadoop (https://github.com/Rodrigo-Beltrao/Hadoop_Hive_GCP) que foi realizado anteriormente com SQL no Hive e agora está sendo feita com PySpark.

<p align="center">
    <img src="https://www.softwebsolutions.com/wp-content/uploads/2016/06/Spark-Hadoop.jpg" alt="Spark">
</p>

## Spark na cloud GCP
Conforme pode ser observado na imagem abaixo, o Spark está devidamente instalado no cluster. No entanto, optei por usar o ambiente Google Colab para realizar as análises com PySpark.

<p align="center">
    <img src="https://i.imgur.com/lOllJhd.png" alt="Spark2">
</p>

## Consultas
Para cada consulta em SQL, foi realizada uma consulta utilizando o PySpark com funções de agregação.

<p align="center">
    <img src="https://i.imgur.com/NThvcAP.png" alt="Spark2">
</p>

## Análises exploratórias
Foram realizadas duas consultas além das realizadas no projeto Hadoop. Essas novas consultas permitiram uma análise exploratória mais detalhada da quantidade de cartões de crédito fraudulentos. Dos 19.936 cartões, apenas 27 são fraudulentos. De acordo com os gráficos abaixo, o número de cartões de crédito fraudulentos representam 0,1% do total de cartões.

<p align="center">
    <img src="https://i.imgur.com/4IyVZKz.png" alt="Spark2">
</p>

